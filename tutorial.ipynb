{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark tutorial\n",
    "\n",
    "This notebook provides basic tutorial of benchmark of bearing fault diagnosis model and optimizer's hyperparameter. Core implementation of this code is in the `fdob` module. This modlue provides data download, data preprocessing, model implementation, quasi-random hyperparameter sampling, and model trainning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/akdakd55/.pyenv/versions/3.9.6/envs/cl/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfdob\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprocessing\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mprocessing\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfdob\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmodel\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39minfo\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbenchmark\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mos\u001b[39;00m\n",
      "File \u001b[0;32m~/cl_ws/FaultDiagnosisBaseline/info.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m fdob\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfdob\u001b[39;00m \u001b[39mimport\u001b[39;00m model\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfdob\u001b[39;00m \u001b[39mimport\u001b[39;00m processing\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import fdob\n",
    "import fdob.processing as processing\n",
    "import fdob.model as model\n",
    "import info\n",
    "import benchmark\n",
    "import sys, os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "from vit_cl import pruning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data download\n",
    "\n",
    "We can download the CWRU and MFPT datasets using `download_cwru` and `download_mfpt`, respectively. These functions automatically download each dataset from URLs and return pandas `DataFrame`. `split_dataframe` splits dataframe to train, validation, and test `Dataframe`. `build_from_dataframe` build `numpy.ndarray` dataset by overlapping. In this tutorial, we use the CWRU dataset for training, and the data is generated with the sample length 4,096 and shift size 2,048."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fdob.download_cwru(\"./data/cwru\")\n",
    "\n",
    "# We exclude label named 999 and 0 HP motor load condition.\n",
    "df = df[(df[\"label\"] != 999) & (df[\"load\"] != 0)]\n",
    "\n",
    "train_df, val_df, test_df = fdob.split_dataframe(df, 0.6, 0.2)\n",
    "\n",
    "X_train, y_train = fdob.build_from_dataframe(train_df, 4096, 2048, False)\n",
    "X_val, y_val = fdob.build_from_dataframe(val_df, 4096, 2048, False)\n",
    "X_test, y_test = fdob.build_from_dataframe(test_df, 4096, 2048, False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the model and preparing `DataLoader`\n",
    "\n",
    "The models and the initial hyperparameter search spaces for each optimizer used in the paper are in the `info.py` file. `info.model` contains the model, input length of the model, and `transform` of data. `info.hparam` contains the information of the search space of four optimizers, sgd, momentum, RMSProp, and adam. Users can employ the models and hyperparameter search space in the `info.py` but also can use the custom models and search space.\n",
    "\n",
    "To train the model using PyTorch Lightning, `DataLoader` should be prepared. We provide `DatasetHandler`, which is the collection of multi-domain datasets. `assign` method generates `DataLoader`, and users can access the `DataLoader` by key of `DataLoader`. This tutorial uses two `DataLoader`s. `DataLoader` with key `cwru` is the noise-free data from the CWRU dataset, and `DataLoader` with key `cwru0` is the noisy data generated by Gaussian noise SNR 0dB from the CWRU dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"transformer\"\n",
    "\n",
    "model = info.model[model_name][\"model\"]\n",
    "sample_length = info.model[model_name][\"sample_length\"]\n",
    "tf_data = info.model[model_name][\"tf\"]\n",
    "tf_label = [processing.NpToTensor()]\n",
    "batch_size = 32\n",
    "num_workers = 1\n",
    "\n",
    "dmodule = fdob.DatasetHandler()\n",
    "\n",
    "dmodule.assign(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    sample_length,\n",
    "    \"cwru\",\n",
    "    transforms.Compose(tf_data),\n",
    "    transforms.Compose(tf_label),\n",
    "    batch_size,\n",
    "    num_workers\n",
    ")\n",
    "\n",
    "dmodule.assign(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    sample_length,\n",
    "    \"cwru0\",\n",
    "    transforms.Compose([processing.AWGN(0)] + tf_data),\n",
    "    transforms.Compose(tf_label),\n",
    "    batch_size,\n",
    "    num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fdob.dataset.NumpyDataset at 0x7fe0541e0520>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access to the DataLoader of train dataset of the noise-free CWRU dataset.\n",
    "dmodule.dataloaders[\"cwru\"][\"train\"]\n",
    "\n",
    "# Access to the Dataset of train dataset of the noisy CWRU dataset.\n",
    "dmodule.dataloaders[\"cwru\"][\"train\"].dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter sampling\n",
    "\n",
    "`log_qsample` samples hyperaprameters in log-scale quasi-random distribution. For example, if adam optimizer and hyperparameter search space defined in `info.py` is used, each hyperparameters are sampled from probability distributions below.\n",
    "\n",
    "* $\\eta \\sim 10^{U[-4, -1]}$\n",
    "* $1 - \\beta_{1} \\sim 10^{U[-3, 0]}$\n",
    "* $1 - \\beta_{2} \\sim 10^{U[-4, -1]}$\n",
    "* $\\epsilon \\sim 10^{U[-10, 0]}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': array([0.0001    , 0.00316228, 0.00056234, 0.01778279]),\n",
       " 'beta1': array([0.999     , 0.99      , 0.9       , 0.99784557]),\n",
       " 'beta2': array([0.9999    , 0.99960189, 0.99841511, 0.99369043]),\n",
       " 'eps': array([1.00000000e-10, 2.68269580e-09, 7.19685673e-08, 1.93069773e-06])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_exps = 4\n",
    "\n",
    "hparam_info = info.hparam[\"adam\"]\n",
    "\n",
    "hparams = fdob.log_qsample(\n",
    "    hparam_info[\"n_params\"],\n",
    "    hparam_info[\"param_names\"],\n",
    "    hparam_info[\"lb\"],\n",
    "    hparam_info[\"ub\"],\n",
    "    hparam_info[\"reversed\"],\n",
    "    n_exps\n",
    ")\n",
    "\n",
    "hparams"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and evaluation\n",
    "\n",
    "To benchmark, following materials should be prepared. \n",
    "\n",
    "* train `DataLoader`\n",
    "* validation `DataLoader`\n",
    "* PyTorch model\n",
    "* model's keyword argument (if there is no keyword argument, pass `None`)\n",
    "* PyTorch optimizer from `torch.optim`\n",
    "* optimizer's keyword argument (if there is no keyword argument, pass `None`)\n",
    "* PyTorch loss function from `torch.nn`\n",
    "* loss function's keyword argument (if there is no keyword argument, pass `None`)\n",
    "* The number of epochs\n",
    "* Random seed (if `None` is passed, random seed is not set)\n",
    "* The number of GPU (only CUDA GPU is supported)\n",
    "* Result directory of the experiemnt\n",
    "\n",
    "Following code train the WDCNN using the first hyperparameter determined above, and the result is saved in the `./logs/mytest`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dmodule.dataloaders[\"cwru\"][\"train\"]\n",
    "val_loader = dmodule.dataloaders[\"cwru\"][\"val\"]\n",
    "\n",
    "seed = 7777\n",
    "n_gpu = 0\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {\n",
    "    \"n_classes\": 10,\n",
    "    \"embed_dim\": 32,\n",
    "    \"depth\": 4,\n",
    "    \"n_heads\": 2,\n",
    "    \"attn_drop\": 0.5,\n",
    "    \"mlp_drop\": 0.5\n",
    "}\n",
    "model_train = model(**model_kwargs)\n",
    "\n",
    "target_sparsity = None\n",
    "\n",
    "prune_conv_only = False\n",
    "\n",
    "callbacks = list()\n",
    "if target_sparsity is not None:\n",
    "    convs = [(module, 'weight') for module in model_train.modules() if isinstance(module, (torch.nn.Conv1d, torch.nn.Conv2d))]\n",
    "\n",
    "    params_to_prune = convs\n",
    "    if not prune_conv_only:\n",
    "        fcs = [(module, 'weight') for module in model_train.modules() if isinstance(module, torch.nn.Linear)][:-1]\n",
    "        params_to_prune = params_to_prune + fcs\n",
    "\n",
    "    pruner = L1UnstructuredPruner()\n",
    "    pruner.register(params_to_prune)\n",
    "\n",
    "    sparsity_scheduler = DefaultSparsityScheduler(final_sparsity=target_sparsity, pruning_steps=n_epochs-1)\n",
    "\n",
    "    pruning_callback = IterativePruningCallback(pruner=pruner, sparsity_scheduler=sparsity_scheduler, frequency=len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_str = ''.join(f'{target_sparsity:.2f}'.split('.')) if target_sparsity else 'noprune'\n",
    "result_dir = f\"./logs/{model_name}_{sparsity_str}\"\n",
    "result_dir = result_dir + '_conv_only' if prune_conv_only else result_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type                | Params\n",
      "------------------------------------------------\n",
      "0 | model   | BaselineTransformer | 91.4 K\n",
      "1 | loss_fn | CrossEntropyLoss    | 0     \n",
      "------------------------------------------------\n",
      "91.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.4 K    Total params\n",
      "0.365     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minha/.pyenv/versions/3.9.6/envs/dfb/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minha/.pyenv/versions/3.9.6/envs/dfb/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/minha/.pyenv/versions/3.9.6/envs/dfb/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1892: PossibleUserWarning: The number of training batches (42) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 55/55 [00:01<00:00, 45.28it/s, loss=0.00362, v_num=0, val_loss=0.174, val_acc=0.995, train_loss=0.0078, train_acc=0.998] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 55/55 [00:01<00:00, 45.04it/s, loss=0.00362, v_num=0, val_loss=0.174, val_acc=0.995, train_loss=0.0078, train_acc=0.998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/minha/.pyenv/versions/3.9.6/envs/dfb/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 112.08it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc             0.995110034942627\n",
      "        test_loss           0.1593620479106903\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 112.14it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.9877750873565674\n",
      "        test_loss           0.17345502972602844\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 108.31it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.5403422713279724\n",
      "        test_loss           1.3887505531311035\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.3887505531311035, 'test_acc': 0.5403422713279724}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = hparam_info[\"optimizer\"]\n",
    "opt_kwargs = {\n",
    "    \"lr\": hparams[\"lr\"][0],\n",
    "    \"betas\": (hparams[\"beta1\"][0], hparams[\"beta2\"][0]),\n",
    "    \"eps\": hparams[\"eps\"][0]\n",
    "}\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss\n",
    "loss_kwargs = None\n",
    "\n",
    "benchmark.train(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    model_train,\n",
    "    model_kwargs,\n",
    "    opt,\n",
    "    opt_kwargs,\n",
    "    loss,\n",
    "    loss_kwargs,\n",
    "    n_epochs,\n",
    "    seed,\n",
    "    n_gpu,\n",
    "    result_dir,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "benchmark.test(\n",
    "    dmodule.dataloaders[\"cwru\"][\"test\"],\n",
    "    model_train,\n",
    "    model_kwargs,\n",
    "    opt,\n",
    "    opt_kwargs,\n",
    "    loss,\n",
    "    loss_kwargs,\n",
    "    n_epochs,\n",
    "    seed,\n",
    "    n_gpu,\n",
    "    result_dir,\n",
    "    \"noise-free\"\n",
    ")\n",
    "benchmark.test(\n",
    "    dmodule.dataloaders[\"cwru0\"][\"test\"],\n",
    "    model,\n",
    "    model_kwargs,\n",
    "    opt,\n",
    "    opt_kwargs,\n",
    "    loss,\n",
    "    loss_kwargs,\n",
    "    n_epochs,\n",
    "    seed,\n",
    "    n_gpu,\n",
    "    result_dir,\n",
    "    \"noise\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/minha/.pyenv/versions/3.9.6/envs/dfb/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 118.61it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.47677260637283325\n",
      "        test_loss           1.4235447645187378\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 115.46it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.47921761870384216\n",
      "        test_loss           1.4352469444274902\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 122.63it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.5012224912643433\n",
      "        test_loss           1.4341174364089966\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 125.14it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.47677260637283325\n",
      "        test_loss           1.4177396297454834\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 133.13it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.5036674737930298\n",
      "        test_loss           1.3770586252212524\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "for seed in [12134234, 25235, 23423, 1212121, 123123]:\n",
    "\n",
    "    benchmark.test(\n",
    "        dmodule.dataloaders[\"cwru0\"][\"test\"],\n",
    "        model,\n",
    "        model_kwargs,\n",
    "        opt,\n",
    "        opt_kwargs,\n",
    "        loss,\n",
    "        loss_kwargs,\n",
    "        n_epochs,\n",
    "        seed,\n",
    "        n_gpu,\n",
    "        result_dir,\n",
    "        \"noise\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/minha/.pyenv/versions/3.9.6/envs/dfb/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 111.72it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.6112469434738159\n",
      "        test_loss           1.2903497219085693\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 118.52it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.6185818910598755\n",
      "        test_loss           1.2987806797027588\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 116.38it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.6088019609451294\n",
      "        test_loss           1.3002971410751343\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 119.36it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc             0.621026873588562\n",
      "        test_loss           1.3395968675613403\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 110.56it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc             0.645476758480072\n",
      "        test_loss           1.2419430017471313\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "for seed in [12134234, 25235, 23423, 1212121, 123123]:\n",
    "\n",
    "    benchmark.test(\n",
    "        dmodule.dataloaders[\"cwru0\"][\"test\"],\n",
    "        model,\n",
    "        model_kwargs,\n",
    "        opt,\n",
    "        opt_kwargs,\n",
    "        loss,\n",
    "        loss_kwargs,\n",
    "        n_epochs,\n",
    "        seed,\n",
    "        n_gpu,\n",
    "        result_dir,\n",
    "        \"noise\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
